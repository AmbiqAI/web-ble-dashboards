<!DOCTYPE html>
<html>

<head>
  <title>Web BLE Audio Test</title>
  <style>
    .container {
      width: 960px;
      height: 384px;
      margin-top: 30px;
      margin-bottom: 7.5px;
      margin: 0 auto;
    }
    .widget {
      background-color: #111111;
      border: 1px solid #000000;
      border-radius: 0px;
      padding: 12px;
      margin: 6px;
      float: left;
      color: #DAE3E3;
      padding-bottom: 16px;
    }
    .doublegraph {
      width: 400px;
      height: 177px;
    }
    .spectrograph {
      height: "512";
      width: "700";
    }
  </style>
  
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>


</head>

<body>
    <form>
        <button id="startNotifications">Pair and start listening to EVB Blue's audio stream</button>
        <button id="stopNotifications">Stop listening</button>
    </form>
    <audio controls></audio>
    <div class="container">
      <div class="double widget">
        <div class="label">Audio Waveform</div>
        <div id="Audio Waveform" class="doublegraph"></div>
      </div>
      <div class="double widget">
        <div class="label">Spectrogram</div>
        <canvas id="Spectrogram" class="doublegraph"></canvas>
      </div>
    </div>
</body>

<script>
    document.querySelector('#startNotifications').addEventListener('click', function(event) {
      event.stopPropagation();
      event.preventDefault();
  
    //   if (isWebBluetoothEnabled()) {
        // ChromeSamples.clearLog();
        onStartButtonClick();
    //   }
    });
    document.querySelector('#stopNotifications').addEventListener('click', function(event) {
      event.stopPropagation();
      event.preventDefault();
  
    //   if (isWebBluetoothEnabled()) {
        onStopButtonClick();
    //   }
    });
  </script>

<script>
    // BLE
    let myCharacteristic;
    let myValue = 0;
    let myBLE;
    const serviceUuid =        '19690000-0000-1234-abcd-5678aabb1011';
    const characteristicUuid = '19690000-5001-1234-abcd-5678aabb1011';

    // Audio Decode
    // let audioContext;
    const audioDecoder = new AudioDecoder({output: decodeToQueue2, error: onAudioError});
    audioDecoder.configure({
            codec: "opus",
            sampleRate: 48000,
            numberOfChannels: 1});
    audioDecoder.flush();

    // Set up MediaStreamGenerator (plays decoded audio)
    const generator = new MediaStreamTrackGenerator({ kind: 'audio' });
    const { writable } = generator;
    const audioWriter = writable.getWriter();
    const mediaStream = new MediaStream([generator]);
    generator.onmute = generator.onunmute = (e) => console.log(e.type);
    const audio = document.querySelector('audio'); // Connect to <audio> element
    audio.srcObject = mediaStream;
    let decoderController = void 0;
    const decoderStream = new ReadableStream({
        start(c) {
        return (decoderController = c);
        },
    });
    const decoderReader = decoderStream.getReader();


    function onStartButtonClick() {
        console.log('Requesting Bluetooth Device...');
        initWaveform();
        navigator.bluetooth.requestDevice({
            filters: [{
                services: [serviceUuid]
            }]
        })
        .then(device => {
            console.log('Connecting to GATT Server...');
            return device.gatt.connect();
        })
        .then(server => {
            console.log('Getting Service...');
            return server.getPrimaryService(serviceUuid);
        })
        .then(service => {
            console.log('Getting Characteristic...');
            return service.getCharacteristic(characteristicUuid);
        })
        .then(characteristic => {
            myCharacteristic = characteristic;
            return myCharacteristic.startNotifications().then(_ => {
                console.log('> Notifications started');
                let spectrogram = new Spectrogram('Spectrogram');
                spectrogram.gotStream(mediaStream);
                myCharacteristic.addEventListener('characteristicvaluechanged',
                    handleNotifications);
            });
        })
        .catch(error => {
            console.log('Argh! ' + error);
        });
    }

    function onStopButtonClick() {
        if (myCharacteristic) {
            myCharacteristic.stopNotifications()
                .then(_ => {
                    console.log('> Notifications stopped');
                    myCharacteristic.removeEventListener('characteristicvaluechanged',
                        handleNotifications);
                })
                .catch(error => {
                    console.log('Argh! ' + error);
                });
        }
    }

    function decodeToQueue (audioData) { // AudioData object
        decodedFrameQueue.push(audioData);
    }

    async function decodeToQueue2 (audioData) { // AudioData object
        ab = new Float32Array(960);
        audioData.copyTo(ab, {planeIndex: 0});
        pcmData = ab; // for animation
        decoderController.enqueue(audioData.duration);
        await audioWriter.write(audioData);
        requestAnimationFrame(updateWaveform);
    }

    function onAudioError(error) {
        console.log(error);
    }

    let chunkNum = 0; // Keeps track of chunk timestamp, starts from time '0'
    function handleNotifications(event) {
        // let value = event.target.value; // This is a DataView
        //  Decode the audio data from the Opus frame
        const init = {
            type: "key",
            data: event.target.value, // This is a DataView
            timestamp: chunkNum*20000,
            duration: 20000,
        };
        chunkNum++;
        chunk = new EncodedAudioChunk(init);
        audioDecoder.decode(chunk);
    }

    // Visualization
    pcmData = []; // for visualization

    function updateWaveform() {
        Plotly.restyle('Audio Waveform', { y: pcmData });
    }

    function initWaveform() {
            var title = 'Audio Waveform';

            Plotly.plot(title, 
            [{
                y: [],
                name: "foo",
                mode: 'lines',
                width: 1,
                line: { width: 1, color:  "#FF355E"}
            }], 
            {
                plot_bgcolor: '#111111',
                paper_bgcolor: '#111111',
                margin: { l: 8, r: 8, b: 18, t: 18 },
                showlegend: false,
                yaxis: {
                'showticklabels': false,
                'autorange': true,
                // 'range': [-32000, 32000]
            },
            xaxis: {
                    'range': [0, 960],
                    'showticklabels': false,
                    'autorange': false,
                    'showgrid': true,
                    'zeroline': true,
                    tickfont: { size: 8 }
                }
            });
        }

// Modified to only show bottom 8khz, since the original data is sampled at 16khz
// Since the encoder is fixed at 48k (so, 24k msx freq), we have to just chop off the top 16k
function Spectrogram(id) {
    var self = this;

    self.canvas = document.getElementById(id);
    self.width  = self.canvas.width;
    self.height = self.canvas.height;
    self.ctx = self.canvas.getContext('2d');
    self.imageData = self.ctx.getImageData(0, 0, self.width, self.height);

    self.data = self.imageData.data;

    self.buf = new ArrayBuffer(self.imageData.data.length);
    self.buf8 = new Uint8ClampedArray(self.buf);
    self.data32 = new Uint32Array(self.buf);

    self.x = 0;
    self.bufferSize = 512;
    self.dataBuffer = new Float32Array(self.height);
    self.uint8array = new Uint8Array(4);
    self.colorData = new Uint8Array(4 * self.bufferSize);

    self.gotStream = function(stream) {
        self.context = new AudioContext();
        self.sampleRate = self.context.sampleRate;

        var input = self.context.createMediaStreamSource(stream);
        self.analyser = self.context.createAnalyser();
        self.analyser.fftSize = self.bufferSize*2;
        input.connect(self.analyser);
        self.animate();
    }

    self.setPixel = function(x, y, red, green, blue, alpha) {
        self.data32[y * self.width + x] =
            (alpha << 24) |    // alpha
            (blue << 16) |      // blue
            (green <<  8) |     // green
            red;                // red
    }

    self.getPixel = function(x, y) {
        var value = self.data32[y * self.width + x];
        var channels = self.uint32Touint8(value)
        return channels;
    }

    self.uint32Touint8 = function(uint32) {
        self.uint8array[3] = uint32 >> 24 & 0xff;
        self.uint8array[2] = uint32 >> 16 & 0xff;
        self.uint8array[1] = uint32 >> 8 & 0xff;
        self.uint8array[0] = uint32 & 0xff;
        return data
    }

    self.drawColumn = function() {
        var value = 0;
        for (var y = 0; y < self.height; y++) {
            var x = col;
            self.setPixel(x, y, value, value, value, 255)
        }
    }

    self.getData = function() {
        var freqByteData = new Uint8Array(self.analyser.frequencyBinCount);
        self.analyser.getByteFrequencyData(freqByteData);

        // Reverse the direction, making lower frequencies on the bottom.
        // BUT we only want to render bottom.
        var startFrom = Math.floor(self.analyser.frequencyBinCount/3);
        // for (var i = self.analyser.frequencyBinCount - 1; i >= 0; i--) {
        for (var i = startFrom - 1; i >= 0; i--) {
            // map whatever freqData number of buckets are present to whatever height we have
            // var pixel = Math.floor((freqByteData.length - i) * self.height / freqByteData.length); // copilot guessed wrong
            var pixel = Math.floor(3*(i) * self.height / freqByteData.length); // fixed
            self.dataBuffer[pixel] = freqByteData[(startFrom - 1) - i] / 255.0;
        }
        return self.dataBuffer
    }

    self.color = function(value) {
        var rgb = {R: 0, G: 0, B: 0};

        if (0 <= value && value <= 1 / 8) {
            rgb.R = 0;
            rgb.G = 0;
            rgb.B = 4 * value + .5; // .5 - 1 // b = 1/2
        } else if (1 / 8 < value && value <= 3 / 8) {
            rgb.R = 0;
            rgb.G = 4 * value - .5; // 0 - 1 // b = - 1/2
            rgb.B = 0;
        } else if (3 / 8 < value && value <= 5 / 8) {
            rgb.R = 4*value - 1.5; // 0 - 1 // b = - 3/2
            rgb.G = 1;
            rgb.B = -4 * value + 2.5; // 1 - 0 // b = 5/2
        } else if (5 / 8 < value && value <= 7 / 8) {
            rgb.R = 1;
            rgb.G = -4 * value + 3.5; // 1 - 0 // b = 7/2
            rgb.B = 0;
        } else if (7 / 8 < value && value <= 1) {
            rgb.R = -4*value + 4.5; // 1 - .5 // b = 9/2
            rgb.G = 0;
            rgb.B = 0;
        } else {    // should never happen - value > 1
            rgb.R = .5;
            rgb.G = 0;
            rgb.B = 0;
        }

        return [rgb.R, rgb.G, rgb.B, 1].map(function(d) { return parseInt(d * 255, 10)})
    }

    self.colorizeData = function(data) {
        var d;
        for(var i = 0, n = data.length; i < n; i++) {
            d = self.color(data[i]);
            self.colorData.set(d, i * 4);
        }
        return self.colorData;
    }

    self.addColumn = function(colorizeData) {
        for (var y = 0; y < self.height; y++) {
            self.setPixel(self.x, y, colorizeData[4 * y + 0], colorizeData[4 * y + 1], colorizeData[4 * y + 2], colorizeData[4 * y + 3]);
        }
        self.x++;
        self.x %= self.width;
    }

    self.drawFrame = function(data) {
        var data = data || self.getData();
        var colorData = self.colorizeData(data)

        self.addColumn(colorData);
        self.imageData.data.set(self.buf8);
        self.ctx.putImageData(self.imageData, 0, 0);
    }

    self.animate = function() {
        self.drawFrame();
        requestAnimationFrame(self.animate);
    }
}



</script>


